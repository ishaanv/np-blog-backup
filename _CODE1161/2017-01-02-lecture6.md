---
layout: post
title: Lecture 6&#58; Working with data
date: 2017-01-10 00:00:00  PDT
type: post
published: true
status: publish
categories: []
tags: []

#this goes on the index page, and into facebook shares
description: Our first intro to getting into some data.

# This is what twitter will pick up if someone tweets the link to this page
# 110 marker 1234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789
twitter-body:
#Twitter and facebook will pick up this image. you can also use it in a post with:
# ![alt text]({{ site.baseurl }}/assets/{{page.featuredimg}})
featuredimg:
---

<style>
  iframe {
      width: 100%;
      height: 820px;
      border: 0;
  }
</style>

<!-- <iframe src="https://docs.google.com/presentation/d/1aWOs9MCDe_HCDj74BWNUbcsML34eK5SUoLwKxfS2uyQ/embed?start=false&loop=false&delayms=3000"></iframe> -->

First thing's first! This is the first week of the second half of the course. That's important because things change a bit from now on.

lab sessions are about you working on your project, with the tutors here to help you get your ideas straightened out.

There's no homework any more, but there is a giant sumbission at the end of week 14, so don't take your foot off the gas!

# Theory

### What do we mean when we say _data_?

That's a big and thorny question! I like to think of it as a lifecycle of sorts. Let me try an analogy and then get back to data.

1. When oil is in the ground, it's not really _oil_ in the sense that we can use it or sell it, it's just plant matter that's in various states of decay.
2. Once it's been pumped out then it's _oil_, Texas tea, crude, black gold. Even then, only a few people want to buy it because it's not all that useful.
3. It goes off to the refinery and is turned into petrol, tar, plastic feedstock, etc. It's useful to a much bigger audience now.
4. We can make the plastic feedstock into bottles and boats and toothbrushes and then it's really useful.
5. That stuff will stick around for a long time, some of it's useful, but a lot of it's junk!

You can call this a process of adding value[^1], and the same is true of data.

1. Configurations of nature exist without us[^2].
2. Through some sort of instrumentation we observe those configurations, and record them. Either as memories through our senses and into our brains, as squiggles on a paper tape with a seismograph, or as binary values on a magnetic disk from a laser scanner. At this point it's crude-data, or as most people say, just _data_.
3. Those data are then collected, aggregated and presented to an observer. That could be our reflective selves, thinking about our memories. It could be the earthquake expert looking at the paper tapes, or it might be the surveyor looking at the results of the laser scan. At this point, I'd like to think of this as _Information_.
4. The observer now has that information in their brain, they fit it in with their existing stock of information. Updating ideas, throwing some out that don't work any more, and finding a place for all the new stuff[^3]. At this point we can usefully call this _knowledge_.
5. Once knowledge has been around for a while, it becomes _wisdom_. I'd caution you to be sceptical when something is presented as wisdom, as it's almost always wrong. The half-life of knowledge[^4] is surprisingly short.

[^1]: We can debate if any value of any value is added, but go with me for the moment.
[^2]: You can also argue that the earth is processing data too. It's a pseudo religious position to take, that all matter is information processing. One that I'm quite sympathetic to, but it's not really the issue at hand here! I'm deliberately taking an anthropocentric view to get the point across, we can be nuanced later.
[^3]: At least that's what is supposed to happen! The brain is way more broken than you'd imagine, what really happens is fascinating, and if you are interested in all the ways that we are irrational, take a look at "Thinking Fast and Slow" By Daniel Kahneman. It's a summary of lots of the important work in that area, and it'll get you started.
[^4]: https://en.wikipedia.org/wiki/Half-life_of_knowledge

### Tiny intro to Information Theory

[Claude Shannon](https://en.wikipedia.org/wiki/Claude_Shannon)[^5] (April 30, 1916 – February 24, 2001) came up with the mathematics and theory of information. A lot of it seems pretty obvious but that's the nice thing about good mathematics, it often does.

The key thing was that you could measure how much information was in some data.

> 0000000000000000

has a lot less information than

> ZW#%Zr3nJpGjB6j6

even though they are both 16 characters long. The minimum amount of information needed to communicate the first is something like `0×16` but there isn't a representation of the second that's any shorter than itself, i.e. `ZW#%Zr3nJpGjB6j6`. This realisation led to all the cool stuff like jpg compression and Netflix.

This is the other way you might hear people talking about information, the mathematical sense of the word.

[^5]: Shannon was another one of the computer heroes, read his wikipedia page, he did some cool stuff, like learning how to beat casinos at blackjack!

### Displaying data

Data vis is so cool these days that it's become almost completely meaningless. Did you leave a coffee ring on a newspaper? Datavis of coffee placement! Did you look at a clock? Datavis of time's relentless passage!

I'm only half mocking these things, they really are data vis in some sense. The wear pattern on your shoes visualises your gait in a really telling way for a forensics person. _But_, let's restrict ourselves to more intentional versions.

The first thing to think about is what sort of data do we have, there are really 3 types:

1. Continuous data, e.g. volume of water in my cup at time _t_
        `143.40` or `75.29403`
2. Discrete data, e.g. how many cups do I have?
        `1` or `7`
        (We can often lump this is with continuous for plotting)
3. Categorical data, e.g. the name of each person who made my cups.
        `Beate` or `Beatrix`

And there's one more special case of continuous that comes up so much that it deserves a special mention: _time_.

The simplest type of plot is where you take categorical values and put them into piles.

![]({{ site.baseurl }}/assets/17/Piles-of-coins.jpg)

People usually think of this as a bar plot.

A special case of bar plots is the histogram. You take a continuous value and depending on where it is you throw it into a bin. A bin might be _values from 0-10_ and then the next will be _values from 10-20_ and so on. If we have a lot of continuous values that aren't time related, it often makes sense to use a histogram.

Histograms are also very useful for statistical analysis. Their shape (mean, spread, skew) can tell you a lot about the data set.

The plot that comes to mind most easily is where you plot _y_ against _x_, usually time, but not always.

![]({{ site.baseurl }}/assets/17/drown_cage.png)

From [spurious correlations](http://www.tylervigen.com/spurious-correlations)

Important things for all charts: title, axis titles (with units), a sense of decency.

It's extremely easy to mislead with charts/graphs/plots, take a look at a graph in a disreputable newspaper and see if it's telling the whole story. There is a load of this sort of stuff in _The Wall Street Journal Guide to Information Graphics_ that's in this week's reading list.

# Technology

We're going to switch environments this week. We're no longer in atom, we're in a Jupyter Notebook.

## Jupyter Notebooks

Notebooks run in your browser. They are a way for you do do exploratory programming.

You can run your code one section at a time. The notebook will maintain state between them too.

This means that you can get a bunch of data into memory, which might take a long time, and then you can prod it all day without having to reload it.

The other important thing is that you can output non-text results. So graphs and tables can easily be produced.

The two libraries we'll be using are Pandas and Matplotlib:

## Pandas :panda_face:

The core library for almost all of the data analysis work in python is `pandas`.

It provides a few really powerful data structures, and a whole load of tools for doing operations on those data.

### Tutorials

The tutorials below are probably the most commonly referenced pandas tutorials. The Pandas Cookbook and Learn Pandas are both already structured into Jupyter Notebooks, so you can play along at home if you download the notebook from their repos.

There also are a gazillion [pandas tutorials on youtube](https://www.youtube.com/results?search_query=pandas+python) so try a few out and see who you like best.

#### [Pandas Cookbook](https://github.com/jvns/pandas-cookbook)
 > The goal of this cookbook is to give you some concrete examples for getting started with pandas.

What more could you want out of life!? This is really nice as a complement to the docs. If there is something that looks a bit hard to understand (and the pandas docs can often be pretty overwhelming!) then this might well have a worked example of how to do that thing.

#### [Learn Pandas](https://bitbucket.org/hrojas/learn-pandas)

This is pretty thorough! Once you've finished this and the cookbook you can pretty much consider yourself a data pro!

#### [Pandas & Seaborn - A guide to handle & visualize data elegantly](https://tryolabs.com/blog/2017/03/16/pandas-seaborn-a-guide-to-handle-visualize-data-elegantly/)

This is a nice intro to pandas, and a [gentle intro to `seaborn`](https://tryolabs.com/blog/2017/03/16/pandas-seaborn-a-guide-to-handle-visualize-data-elegantly/#seaborn), which is a simplified version of `matplotlib`. It uses the Titanic dataset, which is about who was on board the Titanic when it sank. It's got things like each passenger's ticket class and if they survived or not.

![a seaborn jointplot](https://tryolabs.com/images/blog/post-images/2017-03-16-pandas-seaborn-a-guide-to-handle-visualize-data-elegantly/jointplot.png)

#### [So You’d Like To Make a Map Using Python](http://sensitivecities.com/so-youd-like-to-make-a-map-using-python-EN.html#.WPoxsd8xDCI)

I have to admit, I haven't gone through this tutorial, but it looks good. A fairly simple introduction to how to do maps with pandas and choropleth maps. (This one is for people who are feeling brave!)

![Blue Plaque Density, London]({{ site.baseurl }}/assets//17/london_plaque_density.png)

# Talk is cheap, show me the code:

Github does a very nice job of showing notebooks. [Here's this week's one.](https://github.com/notionparallax/code1161base/blob/master/week6/basic_pandas.ipynb) Once you have it downloaded, you can go through it and tweak the variables etc.


# This week's reading :books: / :headphones:

:headphones: **Polich, K.** (2016). [_Let's Kill the Word Cloud._](http://dataskeptic.com/blog/episodes/2016/kill-the-word-cloud)

:books: **Tufte, E.** (2001) [_The Visual Display of Quantitative Information_](https://www.edwardtufte.com/tufte/books_vdqi). Read chapter 4: _Data-Ink and Graphical Redesign_. If you feel so inclined, read the whole book!

:books: **Wong, D.** (2010) _[The Wall Street Journal Guide to Information Graphics<small>: The Dos and Don'ts of Presenting Data, Facts, and Figures</small>](http://www.donawong.com/)_.


# This week's homework

There isn't any _homework_ from now on, but we'll continue to suggest things that you should do. These things are usually vital steps in your data project, that you can bring with you to tutorials to talk through with people.
